import json

from templates.prompting import CTFSolvePrompt
from utility.core_utility import Core
from openai import OpenAI
import warnings
# google.generativeai FutureWarning 억제
warnings.filterwarnings("ignore", category=FutureWarning, message=".*google.generativeai.*")

try:
    from google import genai
except ImportError:
    try:
        import google.generativeai as genai
    except ImportError:
        genai = None

core = Core()

class ExploitAgent:
    def __init__(self, api_key: str, model: str = "gpt-5.2"):
        self.api_key = api_key
        self.model = model
        
        if model == "gpt-5.2":
            self.client = OpenAI(api_key=api_key)
            self.is_gemini = False
        elif model == "gemini-3-flash-preview":
            if genai is None:
                raise ImportError("google-genai package is required for Gemini. Install with: pip install google-genai")
            genai.configure(api_key=api_key)
            self.client = genai.GenerativeModel(model)
            self.is_gemini = True
        else:
            raise ValueError(f"Invalid model: {model}. Supported: gpt-5.2, gemini-3-flash-preview")
    
    def _convert_messages_to_prompt(self, messages):
        """OpenAI messages 형식을 Gemini prompt 텍스트로 변환"""
        prompt_parts = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            
            if role == "developer" or role == "system":
                prompt_parts.append(f"[System/Developer]\n{content}\n")
            elif role == "user":
                prompt_parts.append(f"[User]\n{content}\n")
            elif role == "assistant":
                prompt_parts.append(f"[Assistant]\n{content}\n")
        
        return "\n".join(prompt_parts)
        
    def exploit_run(self, prompt_query: str):
        prompt_exploit = [
            {"role": "developer", "content": CTFSolvePrompt.exploit_prompt},
        ]
        
        state = core.load_json("state.json", default="")
        
        state_msg = {"role": "developer", "content": "[STATE]\n" + json.dumps(state, ensure_ascii=False)}
        user_msg  = {"role": "user", "content": prompt_query}
        
        call_msgs = prompt_exploit + [state_msg, user_msg]

        if self.is_gemini:
            # Gemini API 호출 - 시스템 프롬프트와 대화 분리
            system_parts = []
            user_parts = []
            
            for msg in call_msgs:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if role == "developer" or role == "system":
                    system_parts.append(content)
                elif role == "user":
                    user_parts.append(content)
            
            system_instruction = "\n\n".join(system_parts) if system_parts else None
            user_content = "\n\n".join(user_parts) if user_parts else ""
            
            if system_instruction:
                try:
                    res = self.client.generate_content(
                        user_content,
                        system_instruction=system_instruction
                    )
                except TypeError:
                    full_prompt = f"{system_instruction}\n\n---\n\n{user_content}"
                    res = self.client.generate_content(full_prompt)
            else:
                res = self.client.generate_content(user_content)
            return res.text
        else:
            res = self.client.chat.completions.create(model=self.model, messages=call_msgs)
            return res.choices[0].message.content
    
    def poc_run(self, prompt_query: str):
        """
        PoC 코드 생성 실행
        """
        prompt_poc = [
            {"role": "developer", "content": CTFSolvePrompt.poc_prompt},
        ]
        
        user_msg = {"role": "user", "content": prompt_query}
        
        call_msgs = prompt_poc + [user_msg]

        if self.is_gemini:
            # Gemini API 호출 - 시스템 프롬프트와 대화 분리
            system_parts = []
            user_parts = []
            
            for msg in call_msgs:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if role == "developer" or role == "system":
                    system_parts.append(content)
                elif role == "user":
                    user_parts.append(content)
            
            system_instruction = "\n\n".join(system_parts) if system_parts else None
            user_content = "\n\n".join(user_parts) if user_parts else ""
            
            if system_instruction:
                try:
                    res = self.client.generate_content(
                        user_content,
                        system_instruction=system_instruction
                    )
                except TypeError:
                    full_prompt = f"{system_instruction}\n\n---\n\n{user_content}"
                    res = self.client.generate_content(full_prompt)
            else:
                res = self.client.generate_content(user_content)
            return res.text
        else:
            res = self.client.chat.completions.create(model=self.model, messages=call_msgs)
            return res.choices[0].message.content